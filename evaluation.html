<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Health Data Science in Aotearoa New Zealand: A Practical Guide - 9&nbsp; Evaluation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./deployment-lifecycle.html" rel="next">
<link href="./modelling.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./img/logo-pdh.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Health Data Science in Aotearoa New Zealand: A Practical Guide</span>
    </a>
  </div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Evaluation</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./img/noun-mandatory-1951351.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./starting.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">How do I start?</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./basics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Understanding the basics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./collaboration.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">People, capability &amp; collaboration</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data-landscape.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">The unique health data landscape</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data-access.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Accessing and managing data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data-identifiability.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data identifiability</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data-preparation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data preparation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./modelling.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modelling</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./evaluation.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Evaluation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./deployment-lifecycle.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deployment &amp; lifecycle maintenance</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./glossary.html" class="sidebar-item-text sidebar-link">Glossary</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#model-safety-false-negatives-false-positives" id="toc-model-safety-false-negatives-false-positives" class="nav-link active" data-scroll-target="#model-safety-false-negatives-false-positives"><span class="toc-section-number">9.1</span>  Model safety (false negatives, false positives)</a></li>
  <li><a href="#bias-in-data" id="toc-bias-in-data" class="nav-link" data-scroll-target="#bias-in-data"><span class="toc-section-number">9.2</span>  Bias in data</a></li>
  <li><a href="#clinician-in-the-loop" id="toc-clinician-in-the-loop" class="nav-link" data-scroll-target="#clinician-in-the-loop"><span class="toc-section-number">9.3</span>  Clinician in the loop</a></li>
  <li><a href="#sec-transparency" id="toc-sec-transparency" class="nav-link" data-scroll-target="#sec-transparency"><span class="toc-section-number">9.4</span>  Transparency, interpretability, and explanation</a>
  <ul class="collapse">
  <li><a href="#transparency-around-the-inputs" id="toc-transparency-around-the-inputs" class="nav-link" data-scroll-target="#transparency-around-the-inputs"><span class="toc-section-number">9.4.1</span>  Transparency around the inputs</a></li>
  <li><a href="#interpretation-of-the-output" id="toc-interpretation-of-the-output" class="nav-link" data-scroll-target="#interpretation-of-the-output"><span class="toc-section-number">9.4.2</span>  Interpretation of the output</a></li>
  <li><a href="#transparency-of-algorithm-development" id="toc-transparency-of-algorithm-development" class="nav-link" data-scroll-target="#transparency-of-algorithm-development"><span class="toc-section-number">9.4.3</span>  Transparency of algorithm development</a></li>
  <li><a href="#understanding-the-performance-of-an-algorithm" id="toc-understanding-the-performance-of-an-algorithm" class="nav-link" data-scroll-target="#understanding-the-performance-of-an-algorithm"><span class="toc-section-number">9.4.4</span>  Understanding the performance of an algorithm</a></li>
  <li><a href="#understanding-the-impact-of-an-algorithm" id="toc-understanding-the-impact-of-an-algorithm" class="nav-link" data-scroll-target="#understanding-the-impact-of-an-algorithm"><span class="toc-section-number">9.4.5</span>  Understanding the impact of an algorithm</a></li>
  <li><a href="#principles-to-follow" id="toc-principles-to-follow" class="nav-link" data-scroll-target="#principles-to-follow"><span class="toc-section-number">9.4.6</span>  Principles to follow</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/precisiondrivenhealth/guide.git/edit/main/evaluation.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Evaluation</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>After a model has been created and validated, it should be evaluated to determine whether it can address the question you set out to answer. In some cases this can take the form of a formal prospective data study, where an independent dataset is collected, and the performance of the model on this dataset is assessed. Models that affect patient standard of care will be subject to ethical processes which should be considered upfront - see section on Ethics.</p>
<p>Existing models, such as from other countries or jurisdictions, can also be evaluated against a local dataset, which is a good way to tell how useful someone else’s model may be on your own data.</p>
<p>Lags in data availability can also affect evaluation - a model that goes live today may not be able to be effectively evaluated until several months later.</p>
<p>Possible social and business impacts of model deployment should have been considered in the governance process. Once a model has been deployed, actual impacts can be assessed through data collection, which can also include interviews with interested parties.</p>
<section id="model-safety-false-negatives-false-positives" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="model-safety-false-negatives-false-positives"><span class="header-section-number">9.1</span> Model safety (false negatives, false positives)</h2>
<p>From a clinical perspective the main concern/clinical risk often concerns false negative/low-risk individuals with a positive outcome. Include clinical experts in the discussions on appropriate model thresholds.</p>
<p>When models are implemented, people with high risk will often have additional things done for them to reduce the risk (less of a concern as we are actively doing something to reduce the risk). For the low-risk individuals, there are two possible explanations:</p>
<ol type="1">
<li><p>The outcome was unpredictable</p></li>
<li><p>Additional data could be used for prediction</p></li>
</ol>
<p>It is usually difficult for a data scientist to know what additional data could have been used and it is helpful for the clinical lead to audit a number of false negative results to determine if the outcome was truly unpredictable or if additional data would have helped with the prediction.</p>
</section>
<section id="bias-in-data" class="level2 page-columns page-full" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="bias-in-data"><span class="header-section-number">9.2</span> Bias in data</h2>
<p>Data is collected in a particular context, which leads to bias. This can come from different sources including historical bias, data imbalance, missingness, and human prejudice. There is no single best definition of bias or fairness that applies equally well for every data science application.</p>
<p>While training machine learning models using historically collected data, or drawing any conclusion from data, we should be typically mindful about the potential bias in the data regarding sensitive attributes such as age, ethnicity and gender. Bias-related harms can be reinforced by machine learning models/systems.</p>
<p>Machine learning fairness itself is a broad topic. For a non-exhaustive summary of machine learning fairness from a technical perspective please refer to <a href="https://woki.orionhealth.global/display/DATASCI/ML+Fairness">ML fairness</a>. (Note <span class="citation" data-cites="bellamy_ai_2018">Bellamy et al. <a href="#ref-bellamy_ai_2018" role="doc-biblioref">2018</a></span>)</p>
<div class="no-row-height column-margin column-container"><div id="ref-bellamy_ai_2018" class="csl-entry" role="doc-biblioentry">
Bellamy, R K E, Dey, K, Hind, M, Hoffman, S C, Houde, S, Kannan, K, Lohia, P, Martino, J, Mehta, S, Mojsilovic, A, Nagar, S, Ramamurthy, K N, Richards, J, Saha, D, Sattigeri, P, Singh, M, Varshney, K R, and Zhang, Y. 2018. <span>“<span>AI</span> fairness 360: An extensible toolkit for detecting, understanding, and mitigating unwanted algorithmic bias”</span>. <a href="http://arxiv.org/abs/1810.01943">http://arxiv.org/abs/1810.01943</a>.
</div></div><p>Due to the history focus of cohort studies, certain groups of the population, such as certain ethnic groups, females, might be under-represented and more vulnerable to bias in such studies while any conclusions were drawn or models were trained. In evaluation work, it is important to measure the goodness of fit, accuracy and other metrics of a model from multiple perspectives rather than the overall metrics only. Basic measurement aspects with respect to sensitive attributes (e.g.&nbsp;gender, ethnicity) to be considered:</p>
<ol type="1">
<li><p>The difference of actual patient data metrics stratified by sensitive attributes - whether there is any inequity among the stratified groups, and what bias it may bring into the models</p></li>
<li><p>The difference of predicted outcome metrics stratified by sensitive attributes - whether there is any inequity in model predictions among the stratified groups, and what downstream consequence this may cause</p></li>
<li><p>The difference of model performance metrics among the stratified groups - whether the model is treating the groups equally, and what downstream consequence this may cause</p></li>
</ol>
<p>Reporting metrics with stratification by sensitive attributes whenever applicable can help maintain an equity lens more easily. Performance of the IBIS/Tyrer-Cuzick model of breast cancer risk by race and ethnicity in the Women's Health Initiative is an example <span class="citation" data-cites="kurian_performance_2021">see <a href="#ref-kurian_performance_2021" role="doc-biblioref">Kurian et al. 2021</a></span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-kurian_performance_2021" class="csl-entry" role="doc-biblioentry">
Kurian, A W, Hughes, E, Simmons, T, Bernhisel, R, Probst, B, Meek, S, Caswell‐Jin, J L, John, E M, Lanchbury, J S, Slavin, T P, Wagner, S, Gutin, A, Rohan, T E, Shadyab, A H, Manson, J E, Lane, D, Chlebowski, R T, and Stefanick, M L. 2021. <span>“Performance of the <span>IBIS</span>/tyrer‐cuzick model of breast cancer risk by race and ethnicity in the women’s health initiative”</span>. <em>Cancer</em> 127.20, 3742–3750. <a href="https://onlinelibrary.wiley.com/doi/10.1002/cncr.33767">https://onlinelibrary.wiley.com/doi/10.1002/cncr.33767</a>.
</div></div><p>There is a trade-off between data informativeness / model performance and fairness. Most bias mitigation methods cannot avoid playing with this balance. It is highly recommended to take into account the use case and follow-up impacts while deciding which bias mitigation method to be used and how to use it.</p>
<p>Mitigating bias and improving fairness is mostly not a technical challenge but a much broader systematic challenge.</p>
<p>We recommend including diverse voices and perspectives in data science work, e.g., having a Māori researcher(s) in the project.</p>
<p>Even if no mitigation can be done, it is recommended that the bias itself should be analysed and reported if possible, especially that it is important to identify who is most vulnerable to the bias-related harms.</p>
<p>Tools:</p>
<ul>
<li><p><a href="https://github.com/dssg/aequitas">Aequitas</a></p></li>
<li><p><a href="https://github.com/pymetrics/audit-ai">Audit-AI</a></p></li>
<li><p><a href="https://aif360.mybluemix.net/">AI Fairness 360</a> (IBM)</p></li>
<li><p><a href="https://www.microsoft.com/en-us/research/publication/fairlearn-a-toolkit-for-assessing-and-improving-fairness-in-ai/">Fairlearn</a> (Microsoft)</p></li>
<li><p><a href="https://github.com/linkedin/LiFT">The LinkedIn Fairness Toolkit (LiFT)</a></p></li>
<li><p><a href="https://www.tensorflow.org/responsible_ai/fairness_indicators/guide">Fairness Indicator</a> (Google)</p></li>
<li><p><a href="https://doi.org/10.7326/m18-1376">PROBAST</a></p></li>
</ul>
<p>Further resources:</p>
<ul>
<li><p>FATE: <a href="https://www.microsoft.com/en-us/research/theme/fate/#!publications" class="uri">https://www.microsoft.com/en-us/research/theme/fate/#!publications</a></p></li>
<li><p><a href="https://www.thinkwithgoogle.com/feature/ml-fairness-for-marketers/">https://www.thinkwithgoogle.com/feature/ml-fairness-for-marketers/</a></p></li>
<li><p><a href="https://github.com/google/ml-fairness-gym/blob/master/docs/FAQ.md#What-research-results-have-been-replicated-with-ML-fairness-gym">ML fairness gym</a></p></li>
<li><p><a href="https://www.health.govt.nz/our-work/digital-health/vision-health-technology/emerging-health-technology-advice-and-guidance">Ministry of Health - Emerging Health Technology Advice &amp; Guidance</a></p></li>
</ul>
</section>
<section id="clinician-in-the-loop" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="clinician-in-the-loop"><span class="header-section-number">9.3</span> Clinician in the loop</h2>
<p>expand</p>
</section>
<section id="sec-transparency" class="level2 page-columns page-full" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="sec-transparency"><span class="header-section-number">9.4</span> Transparency, interpretability, and explanation</h2>
<p>In the context of health it is especially important to communicate findings in a way that builds trust in the model development process and outputs. If this is not done well, people may not adopt a model in practice that would otherwise have positive health impacts.</p>
<p>The requirement that models are transparent, interpretable and explainable may guide early modelling decisions such as which algorithm to use and how to treat inputs. Linear models tend to be more interpretable and explainable, so too are models that are built with inputs that have not been subject to significant transformations or weightings. The choice of a ‘simpler’ model may compromise model performance meaning better outcomes are sacrificed for the sake of explainability, however there is little point in deploying a deep learning model that has excellent performance, but is not trusted or used. This trade-off needs to be carefully considered.</p>
<p>Consider outcome measures that are tangible and meaningful to the end user, and that have some relationship to the project goal, such as hospitalisation, mortality, or rankings.</p>
<p>Indicate feature importance and how the model inputs are weighted in relation to model outputs and what that means in practice. For example, if a model includes modifiable inputs, a model user will want to know how changes to that input might affect an outcome. From an equity perspective, a model user will also want to know to what extent inputs such as ethnicity, age, gender or deprivation impact the outcome.</p>
<p>These considerations are also relevant to governance of models. GDPR’s regulation specifically emphasises a model’s transparency, accountability and governance (see <span class="citation" data-cites="kaminski_algorithmic_2021"><a href="#ref-kaminski_algorithmic_2021" role="doc-biblioref">Kaminski and Malgieri 2021</a></span>).</p>
<div class="no-row-height column-margin column-container"><div id="ref-kaminski_algorithmic_2021" class="csl-entry" role="doc-biblioentry">
Kaminski, M E and Malgieri, G. 2021. <span>“Algorithmic impact assessments under the <span>GDPR</span>: Producing multi-layered explanations”</span>. <em>International Data Privacy Law</em> 11.2, 125–144. <a href="https://academic.oup.com/idpl/article/11/2/125/6024963">https://academic.oup.com/idpl/article/11/2/125/6024963</a>.
</div></div><section id="transparency-around-the-inputs" class="level3" data-number="9.4.1">
<h3 data-number="9.4.1" class="anchored" data-anchor-id="transparency-around-the-inputs"><span class="header-section-number">9.4.1</span> Transparency around the inputs</h3>
<p>Provide good data definitions and reasons for how data has been treated e.g “The model includes age but it has been grouped into 3 categories (18-39, 40-59 and 60+) to simplify the model and handle outliers without compromising performance”, and, “The count of regular medications includes medications that have been prescribed in the two years prior to test positive date for this infection. Regular medications are medications that have been prescribed at least four times over that period. Prescription data rather than dispensing data is used as it has better coverage.”</p>
<p>Provide the provenance of data e.g.&nbsp;“This data came from a national collection of data that went through a quality assurance process, it is current and relevant to the problem being answered in this way…”</p>
</section>
<section id="interpretation-of-the-output" class="level3" data-number="9.4.2">
<h3 data-number="9.4.2" class="anchored" data-anchor-id="interpretation-of-the-output"><span class="header-section-number">9.4.2</span> Interpretation of the output</h3>
<p>There are different types of output from different algorithms, e.g.&nbsp;risk scores, predictions, simulation results. In particular, users need to understand what the value means in the context of how it will be used. For example, a risk score of 0.8 might mean 80% probability of an outcome or it may mean something else depending on how the model is built and the use case. If the risk score has been developed for a ranking use case, the end user will need to understand that the output for a given person has meaning in relation to outputs for other people to determine who is at higher risk, rather than as a standalone value.</p>
</section>
<section id="transparency-of-algorithm-development" class="level3 page-columns page-full" data-number="9.4.3">
<h3 data-number="9.4.3" class="anchored" data-anchor-id="transparency-of-algorithm-development"><span class="header-section-number">9.4.3</span> Transparency of algorithm development</h3>
<p>Auditing the behaviour of an algorithm at the population level. For example, does the relationship between the predicted values and certain covariants (e.g.&nbsp;increased predicted mortality risk vs.&nbsp;age) for the validation cohort match with empirical evidence or the clinician’s cognition? Interpretation techniques such as partial dependence plots can facilitate such inspection.</p>
<p>Providing individual level prediction reasoning - provide explanations of the prediction for a specific individual. For example, why the algorithm predicted a 0.86 readmission risk score for a 75 years old Pasifika woman. The score can be attributed to her age, previous hospitalisation history, cancer diagnosis, ethnicity and a few other risk factors. Shapley values is one of the commonly adopted techniques to provide explanations at the individual level. <span class="citation" data-cites="christoph_molnar_interpretable_2022"><a href="#ref-christoph_molnar_interpretable_2022" role="doc-biblioref">Christoph Molnar 2022</a></span> provides more details about model interpretation techniques.</p>
<div class="no-row-height column-margin column-container"><div id="ref-christoph_molnar_interpretable_2022" class="csl-entry" role="doc-biblioentry">
Christoph Molnar. 2022. <span>“Interpretable machine learning”</span>. <a href="https://christophm.github.io/interpretable-ml-book/index.html">https://christophm.github.io/interpretable-ml-book/index.html</a>.
</div></div><p>Clinicians or other stakeholders need to be involved in the population and individual level algorithm auditing, and drive the iterations of the algorithm development with their feedback.</p>
<p>Where possible, making the code base and dataset public adds credibility</p>
</section>
<section id="understanding-the-performance-of-an-algorithm" class="level3" data-number="9.4.4">
<h3 data-number="9.4.4" class="anchored" data-anchor-id="understanding-the-performance-of-an-algorithm"><span class="header-section-number">9.4.4</span> Understanding the performance of an algorithm</h3>
<p>Define performance metrics in the context of the problem. Plain language and accessible explanations not only help build trust in the model, they help the user understand how to use the model, encouraging adoption.</p>
<p>Take, for example, a use case where a model is being used to predict a condition (with prevalence 2%) that requires an intervention. A positive predictive value of 0.95 means that of those people that presented with the condition, 95% were identified by the model. Putting this into context we could say that if 1000 people a day were assessed, we would expect that 20 of them would require the intervention. The model would identify 19 of those people, meaning weekly, 5 people with that condition would be missed if we were to rely solely on model outputs.</p>
<p>Information like this can help a clinician understand that while the model performs well, in practice they might like to supplement model outputs with other assessments.</p>
<p>For models that output probabilities, such as logistic regression, such analyses can be useful in helping clinicians quantify and understand the trade-off between false positives and false negatives in order to decide which decision thresholds may be appropriate.</p>
</section>
<section id="understanding-the-impact-of-an-algorithm" class="level3" data-number="9.4.5">
<h3 data-number="9.4.5" class="anchored" data-anchor-id="understanding-the-impact-of-an-algorithm"><span class="header-section-number">9.4.5</span> Understanding the impact of an algorithm</h3>
<p>Evaluate model benefit and cost in the context of realistic scenarios. With classic model performance metrics such RMSE, accuracy, precision or recall, it is often not enough to illustrate the consequences of integrating the algorithm into a healthcare workflow. It needs to be understood and documented how the algorithm would be integrated in a workflow, and is worth further evaluating what could be the potential healthcare outcome, especially when there is a clinical capacity limitation. For example, a model is developed to classify GP referred patients into high priority and low priority using a certain priority score threshold, and is targeted to facilitate timely triaging. However, in the system there are many people already waiting in the triage queue, people newly referred each day, and the number of triages the clinicians can process has a limit and uncertainty. By just looking at the classification metrics of this model, without knowing at which step of the process this model will be used and how, it is hard to tell exactly whether the integration of the model will bring more benefit than cost in the waiting time for patients who are in urgent need.</p>
<p>Defining proper impact metrics according to the use case and goal of modelling, and carefully running through a further evaluation given the workflow will provide more informative insights than just the classic model performance metrics. Deterministic or stochastic simulation techniques can be applied for such evaluation when a working scenario can be quantitatively described. As a straightforward example, the New Zealand business case for hospital avoidance programme using a readmission risk model presented its financial impact in healthcare (<a href="https://www.econstor.eu/handle/10419/242509">Vaithianathan et al.&nbsp;2012</a>).</p>
</section>
<section id="principles-to-follow" class="level3" data-number="9.4.6">
<h3 data-number="9.4.6" class="anchored" data-anchor-id="principles-to-follow"><span class="header-section-number">9.4.6</span> Principles to follow</h3>
<ul>
<li><p>Closely engage with the stakeholders and data providers (covered in <a href="#end-user-engagement">End-user engagement</a>)</p></li>
<li><p>Keep clinicians in the loop (<a href="#clinician-in-the-loop">Clinician in the loop</a> section heading added)</p></li>
<li><p>Have good quality documentation to share the work with others. <a href="https://pubmed.ncbi.nlm.nih.gov/25560730/">Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis (TRIPOD)</a> provides a well established and practical template for healthcare model reporting. For simpler reporting, consider <a href="https://www.nature.com/articles/s41591-020-1041-y">Minimum information about clinical artificial intelligence modeling: the MI-CLAIM checklist</a> as an alternative. For key information from governance perspective, refer to the governance process and Algorithm Information Request template for the New Zealand Algorithm Hub (<a href="https://algorithmhub.co.nz/about">https://algorithmhub.co.nz/about</a>).</p></li>
<li><p>Version control the code base so that work is reproducible</p></li>
<li><p>Data quality checking: availability including operational concerns, sanity checking, bias</p></li>
<li><p>Equity concerns: who benefits from the algorithm; who may be vulnerable</p></li>
<li><p>Consider your audience when presenting data</p></li>
</ul>



</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
    var links = window.document.querySelectorAll('a:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./modelling.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modelling</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./deployment-lifecycle.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deployment &amp; lifecycle maintenance</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>