<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Health Data Science in Aotearoa New Zealand: A Practical Guide - 9&nbsp; Evaluation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./deployment-lifecycle.html" rel="next">
<link href="./modelling.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./img/logo-pdh.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Health Data Science in Aotearoa New Zealand: A Practical Guide</span>
    </a>
  </div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Evaluation</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./img/noun-mandatory-1951351.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main">
    <a href="https://precisiondrivenhealth.com" title="Precision Driven Health" class="sidebar-tool px-1"><i class="bi bi-globe"></i></a>
    <a href="https://github.com/precisiondrivenhealth/guide" title="GitHub repository" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./starting.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">How do I start?</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./basics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Understanding the basics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./collaboration.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">People, capability &amp; collaboration</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data-landscape.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">The unique health data landscape</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data-access.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Accessing and managing data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data-identifiability.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data identifiability</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data-preparation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data preparation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./modelling.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modelling</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./evaluation.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Evaluation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./deployment-lifecycle.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deployment &amp; lifecycle maintenance</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#model-safety" id="toc-model-safety" class="nav-link active" data-scroll-target="#model-safety"><span class="toc-section-number">9.1</span>  Model safety</a></li>
  <li><a href="#bias-in-data" id="toc-bias-in-data" class="nav-link" data-scroll-target="#bias-in-data"><span class="toc-section-number">9.2</span>  Bias in data</a>
  <ul class="collapse">
  <li><a href="#useful-tools-and-resources" id="toc-useful-tools-and-resources" class="nav-link" data-scroll-target="#useful-tools-and-resources"><span class="toc-section-number">9.2.1</span>  Useful tools and resources</a></li>
  </ul></li>
  <li><a href="#keep-subject-matter-experts-involved-throughout" id="toc-keep-subject-matter-experts-involved-throughout" class="nav-link" data-scroll-target="#keep-subject-matter-experts-involved-throughout"><span class="toc-section-number">9.3</span>  Keep subject matter experts involved throughout</a></li>
  <li><a href="#transparency-interpretability-and-explanation" id="toc-transparency-interpretability-and-explanation" class="nav-link" data-scroll-target="#transparency-interpretability-and-explanation"><span class="toc-section-number">9.4</span>  Transparency, interpretability, and explanation</a>
  <ul class="collapse">
  <li><a href="#transparency-around-the-inputs" id="toc-transparency-around-the-inputs" class="nav-link" data-scroll-target="#transparency-around-the-inputs"><span class="toc-section-number">9.4.1</span>  Transparency around the inputs</a></li>
  <li><a href="#interpretation-of-the-output" id="toc-interpretation-of-the-output" class="nav-link" data-scroll-target="#interpretation-of-the-output"><span class="toc-section-number">9.4.2</span>  Interpretation of the output</a></li>
  <li><a href="#transparency-of-algorithm-development" id="toc-transparency-of-algorithm-development" class="nav-link" data-scroll-target="#transparency-of-algorithm-development"><span class="toc-section-number">9.4.3</span>  Transparency of algorithm development</a></li>
  <li><a href="#understanding-the-performance-of-an-algorithm" id="toc-understanding-the-performance-of-an-algorithm" class="nav-link" data-scroll-target="#understanding-the-performance-of-an-algorithm"><span class="toc-section-number">9.4.4</span>  Understanding the performance of an algorithm</a></li>
  <li><a href="#understanding-the-impact-of-an-algorithm" id="toc-understanding-the-impact-of-an-algorithm" class="nav-link" data-scroll-target="#understanding-the-impact-of-an-algorithm"><span class="toc-section-number">9.4.5</span>  Understanding the impact of an algorithm</a></li>
  <li><a href="#principles-to-follow" id="toc-principles-to-follow" class="nav-link" data-scroll-target="#principles-to-follow"><span class="toc-section-number">9.4.6</span>  Principles to follow</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/precisiondrivenhealth/guide/edit/main/evaluation.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Evaluation</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>After a model has been created and validated, you should evaluate it to determine whether it can address the question you initially set out to answer. In some cases this can take the form of a formal prospective data study, where an independent dataset is collected, and the performance of the model on this dataset is assessed. Models that affect patient standard of care will be subject to ethical processes which should be considered upfront (see <a href="./data-landscape.html#ethics--privacy">Ethics</a>).</p>
<p>Existing models, such as from other countries or jurisdictions, can also be evaluated against a local dataset, which is a good way to tell how useful someone else’s model may be on your own data.</p>
<p>Lags in data availability can affect evaluation: a model that goes live today may not be able to be effectively evaluated until several months later.</p>
<p>Possible social and business impacts of model deployment should be considered in the governance process. Once a model has been deployed, actual impacts can be assessed through data collection, which can also include interviews with interested parties.</p>
<section id="model-safety" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="model-safety"><span class="header-section-number">9.1</span> Model safety</h2>
<p>Making a model safe for use in a healthcare setting generally involves ensuring that its rates of <a href="https://en.wikipedia.org/wiki/False_positives_and_false_negatives">falsely classifying results as positive or negative</a> are low.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>From a clinical perspective, the main area of concern is often false negative or low-risk individuals with a positive outcome. You should include clinical experts in discussions on appropriate model thresholds to address this.</p>
</div>
</div>
<p>When models are implemented, often errors in classifying high-risk individuals can be identified because there is a follow-up step associated with that high risk which aims to reduce the risk. However, errors in classifying low-risk individuals often have two possible explanations:</p>
<ol type="1">
<li><p>The outcome was unpredictable</p></li>
<li><p>Using additional data could improve the accuracy of the model’s prediction</p></li>
</ol>
<p>It is usually difficult for a data scientist to know what additional data could have been used. It’s helpful for your clinical lead to audit a number of false negative results to determine if the outcome is truly unpredictable or if additional data will help with the prediction.</p>
</section>
<section id="bias-in-data" class="level2 page-columns page-full" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="bias-in-data"><span class="header-section-number">9.2</span> Bias in data</h2>
<p>Data is collected in a particular context, which leads to bias. This can come from different sources including historical bias, data imbalance, missingness, and human prejudice. There’s no single best definition of bias or fairness that applies equally well for every data science application.</p>
<p>While training machine learning models using historically collected data, or drawing any conclusion from data, you should be typically mindful about the potential bias in the data, regarding sensitive attributes such as age, ethnicity and gender. Bias-related harms can be reinforced by machine learning models and systems.</p>
<p>The Manatū Hauora Ministry of Health’s <a href="https://www.health.govt.nz/system/files/documents/pages/introductory_guidance_-_algorithms_v0.4_-_web.pdf">Emerging Health Technology Introductory Guidance</a> (PDF) section on Bias is a good place to start learning.</p>
<p>Machine learning fairness is a broad topic; relevant reading includes <a href="https://developers.google.com/machine-learning/crash-course/fairness/video-lecture">a section in Google’s crash course in machine learning</a>, its reference on <a href="https://www.thinkwithgoogle.com/feature/ml-fairness-for-marketers/">A Marketer’s Guide to Machine Learning Fairness</a>, and AI Fairness 360 (<span class="citation" data-cites="bellamy_ai_2018"><a href="#ref-bellamy_ai_2018" role="doc-biblioref">Bellamy et al. 2018</a></span>).</p>
<div class="no-row-height column-margin column-container"><div id="ref-bellamy_ai_2018" class="csl-entry" role="doc-biblioentry">
Bellamy, R K E, Dey, K, Hind, M, Hoffman, S C, Houde, S, Kannan, K, Lohia, P, Martino, J, Mehta, S, Mojsilovic, A, Nagar, S, Ramamurthy, K N, Richards, J, Saha, D, Sattigeri, P, Singh, M, Varshney, K R, and Zhang, Y. 2018. <span>“<span>AI</span> fairness 360: An extensible toolkit for detecting, understanding, and mitigating unwanted algorithmic bias”</span>. <a href="http://arxiv.org/abs/1810.01943">http://arxiv.org/abs/1810.01943</a>.
</div></div><p>Due to the historical focus of cohort studies, certain groups of the population - such as certain ethnic groups or females - may be underrepresented and more vulnerable to bias in studies where any conclusions were drawn or models were trained.</p>
<p>In evaluation work, it’s important to measure the goodness of fit, accuracy and other metrics of a model from multiple perspectives rather than the overall metrics only. Consider the basic measurement aspects with respect to sensitive attributes (for example gender and ethnicity):</p>
<ol type="1">
<li><p>The difference of actual patient data metrics stratified by sensitive attributes - whether there’s any inequity among the stratified groups, and what bias it may bring into the models</p></li>
<li><p>The difference of predicted outcome metrics stratified by sensitive attributes - whether there is any inequity in model predictions among the stratified groups, and what downstream consequence this may cause</p></li>
<li><p>The difference of model performance metrics among the stratified groups - whether the model is treating the groups equally, and what downstream consequence this may cause.</p></li>
</ol>
<p>Reporting metrics with stratification by sensitive attributes whenever applicable can help to more easily maintain an equity lens. Performance of the IBIS/Tyrer-Cuzick model of breast cancer risk by race and ethnicity in the Women’s Health Initiative is an example <span class="citation" data-cites="kurian_performance_2021">see <a href="#ref-kurian_performance_2021" role="doc-biblioref">Kurian et al. 2021</a></span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-kurian_performance_2021" class="csl-entry" role="doc-biblioentry">
Kurian, A W, Hughes, E, Simmons, T, Bernhisel, R, Probst, B, Meek, S, Caswell‐Jin, J L, John, E M, Lanchbury, J S, Slavin, T P, Wagner, S, Gutin, A, Rohan, T E, Shadyab, A H, Manson, J E, Lane, D, Chlebowski, R T, and Stefanick, M L. 2021. <span>“Performance of the <span>IBIS</span>/tyrer‐cuzick model of breast cancer risk by race and ethnicity in the women’s health initiative”</span>. <em>Cancer</em> 127.20, 3742–3750. <a href="https://onlinelibrary.wiley.com/doi/10.1002/cncr.33767">https://onlinelibrary.wiley.com/doi/10.1002/cncr.33767</a>.
</div></div><p>There’s a trade-off between data informativeness, model performance and fairness. Most bias mitigation methods can’t avoid playing with this balance. We highly recommend taking into account the use case and follow-up impacts while deciding which bias mitigation method to be used, and how it’s used.</p>
<p>Mitigating bias and improving fairness is mostly not a technical challenge but a much broader systematic challenge. We recommend including diverse voices and perspectives in data science work by, for example, having Māori researchers involved in your project.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Even if no mitigation can be included, we recommend that the bias itself should be analysed and reported if possible, especially that it is important to identify who is most vulnerable to the bias-related harms.</p>
</div>
</div>
<section id="useful-tools-and-resources" class="level3 page-columns page-full" data-number="9.2.1">
<h3 data-number="9.2.1" class="anchored" data-anchor-id="useful-tools-and-resources"><span class="header-section-number">9.2.1</span> Useful tools and resources</h3>
<ul>
<li><p><a href="https://github.com/dssg/aequitas">Aequitas</a></p></li>
<li><p><a href="https://aif360.mybluemix.net/">AI Fairness 360</a> (IBM)</p></li>
<li><p><a href="https://github.com/pymetrics/audit-ai">Audit-AI</a></p></li>
<li><p><a href="https://www.microsoft.com/en-us/research/publication/fairlearn-a-toolkit-for-assessing-and-improving-fairness-in-ai/">Fairlearn</a> (Microsoft)</p></li>
<li><p><a href="https://www.tensorflow.org/responsible_ai/fairness_indicators/guide">Fairness Indicator</a> (Google)</p></li>
<li><p><a href="https://www.microsoft.com/en-us/research/theme/fate/">FATE: Fairness, Accountability, Transparency, and Ethics in AI</a> (Microsoft)</p></li>
<li><p><a href="https://github.com/linkedin/LiFT">The LinkedIn Fairness Toolkit (LiFT)</a></p></li>
<li><p><a href="https://github.com/google/ml-fairness-gym">ML-fairness-gym</a> (Google)</p></li>
<li><p>PROBAST (see <span class="citation" data-cites="wolff_probast_2019"><a href="#ref-wolff_probast_2019" role="doc-biblioref">Wolff et al. 2019</a></span> and <span class="citation" data-cites="moons_probast_2019"><a href="#ref-moons_probast_2019" role="doc-biblioref">Moons et al. 2019</a></span>)</p></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="ref-wolff_probast_2019" class="csl-entry" role="doc-biblioentry">
Wolff, R F, Moons, K G M, Riley, R D, Whiting, P F, Westwood, M, Collins, G S, Reitsma, J B, Kleijnen, J, and Mallett, S. 2019. <span>“<span>PROBAST</span>: A tool to assess the risk of bias and applicability of prediction model studies”</span>. <em>Annals of Internal Medicine</em> 170.1, 51–58. <a href="https://www.acpjournals.org/doi/10.7326/M18-1376">https://www.acpjournals.org/doi/10.7326/M18-1376</a>.
</div><div id="ref-moons_probast_2019" class="csl-entry" role="doc-biblioentry">
Moons, K G M, Wolff, R F, Riley, R D, Whiting, P F, Westwood, M, Collins, G S, Reitsma, J B, Kleijnen, J, and Mallett, S. 2019. <span>“<span>PROBAST</span>: A tool to assess risk of bias and applicability of prediction model studies: Explanation and elaboration”</span>. <em>Annals of Internal Medicine</em> 170.1, W1. <a href="http://annals.org/article.aspx?doi=10.7326/M18-1377">http://annals.org/article.aspx?doi=10.7326/M18-1377</a>.
</div></div></section>
</section>
<section id="keep-subject-matter-experts-involved-throughout" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="keep-subject-matter-experts-involved-throughout"><span class="header-section-number">9.3</span> Keep subject matter experts involved throughout</h2>
<p>It’s very important to continually engage subject matter experts, such as clinicians, throughout your project. This can encompass involving clinicians in the project as an advisory level, and can be extended by involving clinicians in iterative development of models, such as providing labels.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>It’s incredibly important to keep the perspectives of subject matter experts front of mind throughout your project. If these experts are not involved in the data science process, their acceptance of the outputs will be limited or absent. This may mean your model isn’t able to be used to its full potential - or in the worst case scenario, not used at all.</p>
</div>
</div>
</section>
<section id="transparency-interpretability-and-explanation" class="level2 page-columns page-full" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="transparency-interpretability-and-explanation"><span class="header-section-number">9.4</span> Transparency, interpretability, and explanation</h2>
<p>In the context of health, it’s especially important to communicate findings in a way that builds trust in your model development process and outputs. If trust isn’t built in your model, it may not be adopted in practices.</p>
<p>The requirement for models to be transparent, interpretable and explainable should guide your early modelling decisions, such as which algorithm to use and how to treat inputs. Linear models tend to be more interpretable and explainable; so too are models that are built with inputs that haven’t been subject to significant transformations or weightings.</p>
<p>The choice of a ‘simpler’ model may compromise model performance, meaning better outcomes are sacrificed for the sake of explainability. There is little point however in deploying a deep learning model that has excellent performance, but isn’t trusted or used. You should carefully consider this trade-off.</p>
<p>You should also consider outcome measures that are tangible and meaningful to your end user, and that have some relationship to the project goal, such as hospitalisation, mortality, or rankings.</p>
<p>Finally, you should indicate which inputs are most important to the model performance or model outputs (feature importance) and how the model inputs are weighted in relation to model outputs, and what that means in practice. For example, if a model includes modifiable inputs, a model user will want to know how changes to that input might affect an outcome. From an equity perspective, a model user will also want to know to what extent inputs such as ethnicity, age, gender or deprivation impact the outcome.</p>
<p>These considerations are also relevant to governance of models. GDPR’s regulation specifically emphasises a model’s transparency, accountability and governance (see <span class="citation" data-cites="kaminski_algorithmic_2021"><a href="#ref-kaminski_algorithmic_2021" role="doc-biblioref">Kaminski and Malgieri 2021</a></span>).</p>
<div class="no-row-height column-margin column-container"><div id="ref-kaminski_algorithmic_2021" class="csl-entry" role="doc-biblioentry">
Kaminski, M E and Malgieri, G. 2021. <span>“Algorithmic impact assessments under the <span>GDPR</span>: Producing multi-layered explanations”</span>. <em>International Data Privacy Law</em> 11.2, 125–144. <a href="https://academic.oup.com/idpl/article/11/2/125/6024963">https://academic.oup.com/idpl/article/11/2/125/6024963</a>.
</div></div><section id="transparency-around-the-inputs" class="level3" data-number="9.4.1">
<h3 data-number="9.4.1" class="anchored" data-anchor-id="transparency-around-the-inputs"><span class="header-section-number">9.4.1</span> Transparency around the inputs</h3>
<p>It’s important to provide good data definitions and reasons for how data has been treated. For example:</p>
<ul>
<li>“The model includes age but it has been grouped into 3 categories (18-39, 40-59 and 60+) to simplify the model and handle outliers without compromising performance”; or</li>
<li>“The count of regular medications includes medications that have been prescribed in the two years prior to the test positive date for this infection. Regular medications are medications that have been prescribed at least four times over that period. Prescription data rather than dispensing data is used as it has better coverage.”</li>
</ul>
<p>Providing the provenance of data is also important. For example:</p>
<blockquote class="blockquote">
<p>“This data came from a national collection of data that went through a quality assurance process, it is current and relevant to the problem being answered in this way…”</p>
</blockquote>
</section>
<section id="interpretation-of-the-output" class="level3" data-number="9.4.2">
<h3 data-number="9.4.2" class="anchored" data-anchor-id="interpretation-of-the-output"><span class="header-section-number">9.4.2</span> Interpretation of the output</h3>
<p>There are different types of output from different algorithms, e.g.&nbsp;risk scores, predictions, simulation results. In particular, users need to understand what the value means in the context of how it will be used. For example, a risk score of 0.8 might mean 80% probability of an outcome or it may mean something else depending on how the model is built and the use case. If the risk score has been developed for a ranking use case, the end user will need to understand that the output for a given person has meaning in relation to outputs for other people to determine who is at higher risk, rather than as a standalone value.</p>
</section>
<section id="transparency-of-algorithm-development" class="level3 page-columns page-full" data-number="9.4.3">
<h3 data-number="9.4.3" class="anchored" data-anchor-id="transparency-of-algorithm-development"><span class="header-section-number">9.4.3</span> Transparency of algorithm development</h3>
<p>Auditing the behaviour of an algorithm at the population level. For example, does the relationship between the predicted values and certain covariants (e.g.&nbsp;increased predicted mortality risk vs.&nbsp;age) for the validation cohort match with empirical evidence or the clinician’s cognition? Interpretation techniques such as partial dependence plots can facilitate such inspection.</p>
<p>Providing individual level prediction reasoning - provide explanations of the prediction for a specific individual. For example, why the algorithm predicted a 0.86 readmission risk score for a 75 years old Pasifika woman. The score can be attributed to her age, previous hospitalisation history, cancer diagnosis, ethnicity and a few other risk factors. Shapley values is one of the commonly adopted techniques to provide explanations at the individual level. <span class="citation" data-cites="christoph_molnar_interpretable_2022"><a href="#ref-christoph_molnar_interpretable_2022" role="doc-biblioref">Christoph Molnar 2022</a></span> provides more details about model interpretation techniques.</p>
<div class="no-row-height column-margin column-container"><div id="ref-christoph_molnar_interpretable_2022" class="csl-entry" role="doc-biblioentry">
Christoph Molnar. 2022. <span>“Interpretable machine learning”</span>. <a href="https://christophm.github.io/interpretable-ml-book/index.html">https://christophm.github.io/interpretable-ml-book/index.html</a>.
</div></div><p>Clinicians or other stakeholders need to be involved in the population and individual level algorithm auditing, and drive the iterations of the algorithm development with their feedback.</p>
<p>Where possible, making the code base and dataset public adds credibility</p>
</section>
<section id="understanding-the-performance-of-an-algorithm" class="level3" data-number="9.4.4">
<h3 data-number="9.4.4" class="anchored" data-anchor-id="understanding-the-performance-of-an-algorithm"><span class="header-section-number">9.4.4</span> Understanding the performance of an algorithm</h3>
<p>Define performance metrics in the context of the problem. Plain language and accessible explanations not only help build trust in the model, they help the user understand how to use the model, encouraging adoption.</p>
<p>Take, for example, a use case where a model is being used to predict a condition (with prevalence 2%) that requires an intervention. A positive predictive value of 0.95 means that of those people that presented with the condition, 95% were identified by the model. Putting this into context we could say that if 1000 people a day were assessed, we would expect that 20 of them would require the intervention. The model would identify 19 of those people, meaning weekly, 5 people with that condition would be missed if we were to rely solely on model outputs.</p>
<p>Information like this can help a clinician understand that while the model performs well, in practice they might like to supplement model outputs with other assessments.</p>
<p>For models that output probabilities, such as logistic regression, such analyses can be useful in helping clinicians quantify and understand the trade-off between false positives and false negatives in order to decide which decision thresholds may be appropriate.</p>
</section>
<section id="understanding-the-impact-of-an-algorithm" class="level3" data-number="9.4.5">
<h3 data-number="9.4.5" class="anchored" data-anchor-id="understanding-the-impact-of-an-algorithm"><span class="header-section-number">9.4.5</span> Understanding the impact of an algorithm</h3>
<p>Evaluate model benefit and cost in the context of realistic scenarios. With classic model performance metrics such RMSE, accuracy, precision or recall, it is often not enough to illustrate the consequences of integrating the algorithm into a healthcare workflow. It needs to be understood and documented how the algorithm would be integrated in a workflow, and is worth further evaluating what could be the potential healthcare outcome, especially when there is a clinical capacity limitation. For example, a model is developed to classify GP referred patients into high priority and low priority using a certain priority score threshold, and is targeted to facilitate timely triaging. However, in the system there are many people already waiting in the triage queue, people newly referred each day, and the number of triages the clinicians can process has a limit and uncertainty. By just looking at the classification metrics of this model, without knowing at which step of the process this model will be used and how, it is hard to tell exactly whether the integration of the model will bring more benefit than cost in the waiting time for patients who are in urgent need.</p>
<p>Defining proper impact metrics according to the use case and goal of modelling, and carefully running through a further evaluation given the workflow will provide more informative insights than just the classic model performance metrics. Deterministic or stochastic simulation techniques can be applied for such evaluation when a working scenario can be quantitatively described. As a straightforward example, the New Zealand business case for hospital avoidance programme using a readmission risk model presented its financial impact in healthcare (<a href="https://www.econstor.eu/handle/10419/242509">Vaithianathan et al.&nbsp;2012</a>).</p>
</section>
<section id="principles-to-follow" class="level3" data-number="9.4.6">
<h3 data-number="9.4.6" class="anchored" data-anchor-id="principles-to-follow"><span class="header-section-number">9.4.6</span> Principles to follow</h3>
<ul>
<li><p>Closely engage with the stakeholders and data providers (covered in <a href="collaboration.html#end-user-engagement">End-user engagement</a>)</p></li>
<li><p>Keep clinicians in the loop (<a href="#clinician-in-the-loop">Clinician in the loop</a> section heading added)</p></li>
<li><p>Have good quality documentation to share the work with others. <a href="https://pubmed.ncbi.nlm.nih.gov/25560730/">Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis (TRIPOD)</a> provides a well established and practical template for healthcare model reporting. For simpler reporting, consider <a href="https://www.nature.com/articles/s41591-020-1041-y">Minimum information about clinical artificial intelligence modeling: the MI-CLAIM checklist</a> as an alternative. For key information from governance perspective, refer to the governance process and Algorithm Information Request template for the New Zealand Algorithm Hub (<a href="https://algorithmhub.co.nz/about">https://algorithmhub.co.nz/about</a>).</p></li>
<li><p>Version control the code base so that work is reproducible</p></li>
<li><p>Data quality checking: availability including operational concerns, sanity checking, bias</p></li>
<li><p>Equity concerns: who benefits from the algorithm; who may be vulnerable</p></li>
<li><p>Consider your audience when presenting data</p></li>
</ul>



</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
    var links = window.document.querySelectorAll('a:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./modelling.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modelling</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./deployment-lifecycle.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deployment &amp; lifecycle maintenance</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>