
@article{kaminski_algorithmic_2021,
	title = {Algorithmic impact assessments under the {GDPR}: producing multi-layered explanations},
	volume = {11},
	issn = {2044-3994, 2044-4001},
	url = {https://academic.oup.com/idpl/article/11/2/125/6024963},
	doi = {10.1093/idpl/ipaa020},
	shorttitle = {Algorithmic impact assessments under the {GDPR}},
	pages = {125--144},
	number = {2},
	journaltitle = {International Data Privacy Law},
	author = {Kaminski, Margot E and Malgieri, Gianclaudio},
	date = {2021-08-06},
	langid = {english},
}

@online{christoph_molnar_interpretable_2022,
	title = {Interpretable Machine Learning},
	url = {https://christophm.github.io/interpretable-ml-book/index.html},
	author = {{Christoph Molnar}},
	date = {2022-10-22},
}

@online{precision_driven_health_aotearoa_2022,
	title = {Aotearoa {NZ} Data Sources Review},
	url = {https://data.precisiondrivenhealth.com},
	author = {{Precision Driven Health}},
	date = {2022},
}

@article{kurian_performance_2021,
	title = {Performance of the {IBIS}/Tyrer‐Cuzick model of breast cancer risk by race and ethnicity in the Women's Health Initiative},
	volume = {127},
	issn = {0008-543X, 1097-0142},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/cncr.33767},
	doi = {10.1002/cncr.33767},
	pages = {3742--3750},
	number = {20},
	journaltitle = {Cancer},
	shortjournal = {Cancer},
	author = {Kurian, Allison W. and Hughes, Elisha and Simmons, Timothy and Bernhisel, Ryan and Probst, Braden and Meek, Stephanie and Caswell‐Jin, Jennifer L. and John, Esther M. and Lanchbury, Jerry S. and Slavin, Thomas P. and Wagner, Susanne and Gutin, Alexander and Rohan, Thomas E. and Shadyab, Aladdin H. and Manson, {JoAnn} E. and Lane, Dorothy and Chlebowski, Rowan T. and Stefanick, Marcia L.},
	date = {2021-10-15},
	langid = {english},
}

@misc{bellamy_ai_2018,
	title = {{AI} Fairness 360: An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias},
	url = {http://arxiv.org/abs/1810.01943},
	shorttitle = {{AI} Fairness 360},
	abstract = {Fairness is an increasingly important concern as machine learning models are used to support decision making in high-stakes applications such as mortgage lending, hiring, and prison sentencing. This paper introduces a new open source Python toolkit for algorithmic fairness, {AI} Fairness 360 ({AIF}360), released under an Apache v2.0 license \{https://github.com/ibm/aif360). The main objectives of this toolkit are to help facilitate the transition of fairness research algorithms to use in an industrial setting and to provide a common framework for fairness researchers to share and evaluate algorithms. The package includes a comprehensive set of fairness metrics for datasets and models, explanations for these metrics, and algorithms to mitigate bias in datasets and models. It also includes an interactive Web experience (https://aif360.mybluemix.net) that provides a gentle introduction to the concepts and capabilities for line-of-business users, as well as extensive documentation, usage guidance, and industry-specific tutorials to enable data scientists and practitioners to incorporate the most appropriate tool for their problem into their work products. The architecture of the package has been engineered to conform to a standard paradigm used in data science, thereby further improving usability for practitioners. Such architectural design and abstractions enable researchers and developers to extend the toolkit with their new algorithms and improvements, and to use it for performance benchmarking. A built-in testing infrastructure maintains code quality.},
	number = {{arXiv}:1810.01943},
	publisher = {{arXiv}},
	author = {Bellamy, Rachel K. E. and Dey, Kuntal and Hind, Michael and Hoffman, Samuel C. and Houde, Stephanie and Kannan, Kalapriya and Lohia, Pranay and Martino, Jacquelyn and Mehta, Sameep and Mojsilovic, Aleksandra and Nagar, Seema and Ramamurthy, Karthikeyan Natesan and Richards, John and Saha, Diptikalyan and Sattigeri, Prasanna and Singh, Moninder and Varshney, Kush R. and Zhang, Yunfeng},
	date = {2018-10-03},
	eprinttype = {arxiv},
	eprint = {1810.01943 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/kellya/Zotero/storage/45BCXUWL/Bellamy et al. - 2018 - AI Fairness 360 An Extensible Toolkit for Detecti.pdf:application/pdf;arXiv.org Snapshot:/Users/kellya/Zotero/storage/Q7INKBUC/1810.html:text/html},
}

@incollection{george_data_2020,
	title = {Data Ethics and Data Governance from A Māori World View},
	isbn = {978-1-78769-390-6 978-1-78769-389-0},
	url = {https://www.emerald.com/insight/content/doi/10.1108/S2398-601820200000006005/full/html},
	pages = {67--81},
	booktitle = {Advances in Research Ethics and Integrity},
	publisher = {Emerald Publishing Limited},
	author = {West, Kiri and Hudson, Maui and Kukutai, Tahu},
	editor = {George, Lily and Tauri, Juan and {MacDonald}, Lindsey Te Ata o Tu},
	date = {2020-10-19},
	doi = {10.1108/S2398-601820200000006005},
}

@inproceedings{tse_challenges_2018,
	title = {The Challenges of Big Data Governance in Healthcare},
	doi = {10.1109/TrustCom/BigDataSE.2018.00240},
	abstract = {Big data starts to be employed in some industries but not yet widely or properly adopted in healthcare industry. This research paper aims at studying the usages and challenges of big data in healthcare sector. Governance of big data will include the domains of strategy, process, people, policy and technology and automation. Among the challenges identified in the healthcare sector, reliability and integrity are especially important because it is related to life and death. Big data governance for policy maker, authentication for data integrity, and future development of healthcare big data governance are discussed here. Moreover, some future development questions are raised in this paper for further study, which will improve the quality of life and lead to a better and healthier world under the proper and adequate big data governance environment.},
	eventtitle = {2018 17th {IEEE} International Conference On Trust, Security And Privacy In Computing And Communications/ 12th {IEEE} International Conference On Big Data Science And Engineering ({TrustCom}/{BigDataSE})},
	pages = {1632--1636},
	booktitle = {2018 17th {IEEE} International Conference On Trust, Security And Privacy In Computing And Communications/ 12th {IEEE} International Conference On Big Data Science And Engineering ({TrustCom}/{BigDataSE})},
	author = {Tse, Daniel and Chow, Chung-kin and Ly, Ting-pong and Tong, Chung-yan and Tam, Kwok-wah},
	date = {2018-08},
	note = {{ISSN}: 2324-9013},
	keywords = {big data, Big Data, challenges, Conferences, Data privacy, governance, Handheld computers, healthcare, Security},
	file = {IEEE Xplore Abstract Record:/Users/kellya/Zotero/storage/4AQ5HQBA/8456108.html:text/html},
}

@article{alhassan_data_2016,
	title = {Data governance activities: an analysis of the literature},
	volume = {25},
	issn = {1246-0125},
	url = {https://doi.org/10.1080/12460125.2016.1187397},
	doi = {10.1080/12460125.2016.1187397},
	shorttitle = {Data governance activities},
	abstract = {Data governance is an emerging subject in the information system ({IS}) field. In recent years, the volume of data used within organisations has increased dramatically, playing a critical role in business operations. This paper explores the current literature on data governance and is intended to provide a comprehensive analysis of the activities involved in data governance. Six major academic databases in the {IS} domain were searched using key terms to identify and analyse material reflecting the current state of knowledge. A systematic procedure was developed to identify 31 papers that explicitly mention data governance activities. Open coding techniques were applied to conduct content analysis, resulting in 110 data governance activities across five decision domains of the data governance framework. These data governance activities are understood as: ‘action’ plus ‘area of governance’ plus ‘decision domain’ e.g. (define data policies for data quality). Our analysis shows a high volume of data governance activities associated with the ‘defining’ action of the areas of governance across the decision domains with a lack of reported on the ‘implementing’ and ‘monitoring’ actions.},
	pages = {64--75},
	issue = {sup1},
	journaltitle = {Journal of Decision Systems},
	author = {Alhassan, Ibrahim and Sammon, David and Daly, Mary},
	date = {2016-06-10},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/12460125.2016.1187397},
	keywords = {content analysis, Data governance, data governance activities, open coding},
	file = {Full Text:/Users/kellya/Zotero/storage/VAX4Q654/Alhassan et al. - 2016 - Data governance activities an analysis of the lit.pdf:application/pdf},
}

@online{nhs_england_guide_2021,
	title = {A guide to good practice for digital and data-driven health technologies},
	url = {https://www.gov.uk/government/publications/code-of-conduct-for-data-driven-health-and-care-technology/initial-code-of-conduct-for-data-driven-health-and-care-technology},
	titleaddon = {{GOV}.{UK}},
	author = {{NHS England}},
	date = {2021-01-19},
	langid = {english},
	file = {Snapshot:/Users/kellya/Zotero/storage/YAG4N6TD/initial-code-of-conduct-for-data-driven-health-and-care-technology.html:text/html},
}

@online{manatu_hauora_ministry_of_health_algorithm_nodate,
	title = {The Algorithm Charter},
	url = {https://www.health.govt.nz/our-work/digital-health/digital-health-sector-architecture-standards-and-governance/algorithm-charter},
	abstract = {The Algorithm Charter is a commitment by government agencies to manage their use of algorithms in a fair, ethical, and transparent way.},
	author = {{Manatū Hauora Ministry of Health}},
	langid = {english},
	file = {Snapshot:/Users/kellya/Zotero/storage/7FXG7QTB/algorithm-charter.html:text/html},
}

@online{datagovtnz_algorithm_nodate,
	title = {Algorithm charter for Aotearoa New Zealand},
	url = {https://www.data.govt.nz/toolkit/data-ethics/government-algorithm-transparency-and-accountability/algorithm-charter/},
	author = {{Data.govt.nz}},
	file = {Algorithm charter for Aotearoa New Zealand - data.govt.nz:/Users/kellya/Zotero/storage/WVJLW5SB/algorithm-charter.html:text/html},
}

@online{noauthor_research_nodate,
	title = {Research and engagement — Digital Identity Programme},
	url = {https://www.digital.govt.nz/digital-government/programmes-and-projects/digital-identity-programme/research-and-engagement-digital-identity-programme/},
	abstract = {Four main issues related to trust, privacy and security, ease of use and data handling practices were highlighted through extensive engagement with a range of stakeholders.},
	titleaddon = {New Zealand Digital government},
	langid = {newzealand},
}

@online{manatu_hauora_ministry_of_health_how_nodate,
	title = {How to access data},
	url = {https://www.health.govt.nz/nz-health-statistics/access-and-use/how-access-data},
	abstract = {Where to find published data from national collections and surveys, and how to request unpublished data, including Confidentialised Unit Record Files from population surveys.},
	titleaddon = {Ministry of Health {NZ}},
	author = {{Manatū Hauora Ministry of Health}},
	langid = {english},
	file = {Snapshot:/Users/kellya/Zotero/storage/6FESDLSW/how-access-data.html:text/html},
}

@collection{earley_dama-dmbok_2017,
	location = {Basking Ridge, New Jersey},
	edition = {2nd edition},
	title = {{DAMA}-{DMBOK}: data management body of knowledge},
	isbn = {978-1-63462-234-9},
	shorttitle = {{DAMA}-{DMBOK}},
	abstract = {This guide provides information on data governance, data architecture, data development, database operations, data security, reference and master data, data warehousing and business intelligence, document and content management, meta data management, data quality and professional development. {DAMA}-{DMBOK}2 provides data management and {IT} professionals, executives, knowledge workers, educators, and researchers with a framework to manage their data and mature their information infrastructure},
	pagetotal = {624},
	publisher = {Technics Publications},
	editor = {Earley, Susan and Henderson, Deborah and Data Management Association},
	date = {2017},
	note = {{OCLC}: ocn993697506},
	keywords = {Database management, Electronic data processing, Information technology, Management},
}

@inreference{noauthor_cross-industry_2022,
	title = {Cross-industry standard process for data mining},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Cross-industry_standard_process_for_data_mining},
	abstract = {Cross-industry standard process for data mining, known as {CRISP}-{DM}, is an open standard process model that describes common approaches used by data mining experts. It is the most widely-used analytics model.In 2015, {IBM} released a new methodology called Analytics Solutions Unified Method for Data Mining/Predictive Analytics (also known as {ASUM}-{DM}) which refines and extends {CRISP}-{DM}.},
	booktitle = {Wikipedia},
	date = {2022-10-20},
	langid = {english},
	note = {Page Version {ID}: 1117200778},
	file = {Snapshot:/Users/kellya/Zotero/storage/DZF23HXW/Cross-industry_standard_process_for_data_mining.html:text/html},
}

@inproceedings{mitchell_model_2019,
	title = {Model Cards for Model Reporting},
	url = {http://arxiv.org/abs/1810.03993},
	doi = {10.1145/3287560.3287596},
	abstract = {Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model. To solidify the concept, we provide cards for two supervised models: One trained to detect smiling faces in images, and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related {AI} technology, increasing transparency into how well {AI} technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation.},
	pages = {220--229},
	booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
	author = {Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
	date = {2019-01-29},
	eprinttype = {arxiv},
	eprint = {1810.03993 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/kellya/Zotero/storage/CGDQHF4X/Mitchell et al. - 2019 - Model Cards for Model Reporting.pdf:application/pdf;arXiv.org Snapshot:/Users/kellya/Zotero/storage/MIHBPC2G/1810.html:text/html},
}

@online{noauthor_tripod_nodate,
	title = {{TRIPOD} statement},
	url = {https://www.tripod-statement.org/resources/},
	file = {Tripod statement:/Users/kellya/Zotero/storage/YM44B97R/resources.html:text/html},
}

@article{collins_transparent_2015,
	title = {Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis ({TRIPOD}): The {TRIPOD} Statement},
	volume = {162},
	issn = {0003-4819, 1539-3704},
	url = {https://www.acpjournals.org/doi/10.7326/M14-0697},
	doi = {10.7326/M14-0697},
	shorttitle = {Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis ({TRIPOD})},
	pages = {55--63},
	number = {1},
	journaltitle = {Annals of Internal Medicine},
	shortjournal = {Ann Intern Med},
	author = {Collins, Gary S. and Reitsma, Johannes B. and Altman, Douglas G. and Moons, Karel G.M.},
	date = {2015-01-06},
	langid = {english},
	file = {Submitted Version:/Users/kellya/Zotero/storage/4IKLQVZY/Collins et al. - 2015 - Transparent Reporting of a multivariable predictio.pdf:application/pdf},
}

@online{microsoft_team_nodate,
	title = {Team Data Science Process for data scientists - Azure Architecture Center},
	url = {https://learn.microsoft.com/en-us/azure/architecture/data-science-process/team-data-science-process-for-data-scientists},
	abstract = {Guidance on a set of objectives that are typically used to implement comprehensive data science solutions with Azure technologies using the Team Data Science Process and Azure Machine Learning.},
	author = {{Microsoft}},
	langid = {english},
	file = {Snapshot:/Users/kellya/Zotero/storage/AUUUY9YE/team-data-science-process-for-data-scientists.html:text/html},
}

@online{noauthor_tfx_nodate,
	title = {The {TFX} User Guide},
	url = {https://www.tensorflow.org/tfx/guide},
	titleaddon = {{TensorFlow}},
	langid = {english},
	file = {Snapshot:/Users/kellya/Zotero/storage/EBUDS7HS/guide.html:text/html},
}

@online{noauthor_new_2021,
	title = {New Zealand Health Sector Algorithm Scan},
	url = {https://precisiondrivenhealth.com/new-zealand-health-sector-algorithm-scan/},
	abstract = {The final report of the New Zealand Health and Disability System review makes clear the vision for a ‘data-driven, digitally-enabled ecosystem’ in New Zealand and the need for ‘te…},
	titleaddon = {Precision Driven Health},
	date = {2021-12-12},
	langid = {newzealand},
	file = {Snapshot:/Users/kellya/Zotero/storage/BK4YHS4C/new-zealand-health-sector-algorithm-scan.html:text/html},
}

@online{noauthor_emerging_nodate,
	title = {Emerging health technology - advice and guidance},
	url = {https://www.health.govt.nz/our-work/digital-health/vision-health-technology/emerging-health-technology-advice-and-guidance},
	abstract = {Information and advice on emerging health technologies in the health and disability sector. These may be useful to people and organisations that use technology or want to know more about it during the {COVID}-19 response.},
	titleaddon = {Ministry of Health {NZ}},
	langid = {english},
	file = {Snapshot:/Users/kellya/Zotero/storage/6FZAWF9A/emerging-health-technology-advice-and-guidance.html:text/html},
}

@article{shearer_crisp-dm_2000,
	title = {The {CRISP}-{DM} Model: The New Blueprint for Data Mining},
	volume = {5},
	pages = {13--22},
	number = {4},
	journaltitle = {Journal of Data Warehousing},
	author = {Shearer, C},
	date = {2000},
	file = {Shearer - 2000 - The CRISP-DM Model The New Blueprint for Data Min.pdf:/Users/kellya/Zotero/storage/HNGKQN3I/Shearer - 2000 - The CRISP-DM Model The New Blueprint for Data Min.pdf:application/pdf},
}

@online{yan_practical_2020,
	title = {A Practical Guide to Maintaining Machine Learning in Production},
	url = {https://eugeneyan.com/writing/practical-guide-to-maintaining-machine-learning/},
	abstract = {Can maintaining machine learning in production be easier? I go through some practical tips.},
	titleaddon = {eugeneyan.com},
	author = {Yan, Eugene},
	date = {2020-05-25},
	langid = {english},
	note = {Section: posts},
	file = {Snapshot:/Users/kellya/Zotero/storage/MXJ73XT7/practical-guide-to-maintaining-machine-learning.html:text/html},
}

@software{university_of_chicago_center_for_data_science_and_public_policy_aequitas_2022,
	title = {Aequitas: The Bias and Fairness Audit Toolkit},
	rights = {{MIT}},
	url = {https://github.com/dssg/aequitas},
	publisher = {Data Science for Social Good},
	author = {{University of Chicago Center for Data Science and Public Policy}},
	date = {2022-10-31},
	note = {original-date: 2018-02-13T19:40:30Z},
	keywords = {bias, fairness, fairness-testing, machine-bias},
}

@software{noauthor_audit-ai_2022,
	title = {audit-{AI}},
	rights = {{MIT}},
	url = {https://github.com/pymetrics/audit-ai},
	abstract = {Open Sourced Bias Testing for Generalized Machine Learning Applications. Detect demographic differences in the output of machine learning models or other assessments},
	publisher = {Pymetrics},
	date = {2022-10-05},
	note = {original-date: 2018-05-17T20:08:23Z},
}

@online{noauthor_ai_nodate,
	title = {{AI} Fairness 360},
	url = {https://aif360.mybluemix.net/},
	file = {AI Fairness 360:/Users/kellya/Zotero/storage/JQ6P9M5K/aif360.mybluemix.net.html:text/html},
}

@report{bird_fairlearn_2020,
	title = {Fairlearn: A toolkit for assessing and improving fairness in {AI}},
	url = {https://www.microsoft.com/en-us/research/publication/fairlearn-a-toolkit-for-assessing-and-improving-fairness-in-ai/},
	abstract = {We introduce Fairlearn, an open source toolkit that empowers data scientists and developers to assess and improve the fairness of their {AI} systems. Fairlearn has two components: an interactive visualization dashboard and unfairness mitigation algorithms. These components are designed to help with navigating trade-offs between fairness and model performance. We emphasize that prioritizing fairness in {AI} systems is a sociotechnical challenge. Because there are many complex sources of unfairness—some societal and some technical—it is not possible to fully “debias” a system or to guarantee fairness; the goal is to mitigate fairness-related harms as much as possible. As Fairlearn grows to include additional fairness metrics, unfairness mitigation algorithms, and visualization capabilities, we hope that it will be shaped by a diverse community of stakeholders, ranging from data scientists, developers, and business decision makers to the people whose lives may be affected by the predictions of {AI} systems.},
	number = {{MSR}-{TR}-2020-32},
	institution = {Microsoft},
	author = {Bird, Sarah and Dudík, Miro and Edgar, Richard and Horn, Brandon and Lutz, Roman and Milan, Vanessa and Sameki, Mehrnoosh and Wallach, Hanna and Walker, Kathleen},
	date = {2020-05},
}

@software{noauthor_linkedin_2022,
	title = {The {LinkedIn} Fairness Toolkit ({LiFT})},
	rights = {{BSD}-2-Clause},
	url = {https://github.com/linkedin/LiFT},
	abstract = {The {LinkedIn} Fairness Toolkit ({LiFT}) is a Scala/Spark library that enables the measurement of fairness in large scale machine learning workflows.},
	publisher = {{LinkedIn}},
	date = {2022-11-02},
	note = {original-date: 2020-07-01T22:17:55Z},
	keywords = {fairness, fairness-ai, fairness-ml, linkedin, machine-learning, scala, spark},
}

@online{noauthor_fairness_nodate,
	title = {Fairness Indicators {\textbar} Responsible {AI} Toolkit},
	url = {https://www.tensorflow.org/responsible_ai/fairness_indicators/guide},
	abstract = {Fairness Indicators tool suite for {TensorFlow}.},
	titleaddon = {{TensorFlow}},
	langid = {english},
}

@article{wolff_probast_2019,
	title = {{PROBAST}: A Tool to Assess the Risk of Bias and Applicability of Prediction Model Studies},
	volume = {170},
	issn = {0003-4819},
	url = {https://www.acpjournals.org/doi/10.7326/M18-1376},
	doi = {10.7326/M18-1376},
	shorttitle = {{PROBAST}},
	pages = {51--58},
	number = {1},
	journaltitle = {Annals of Internal Medicine},
	shortjournal = {Ann Intern Med},
	author = {Wolff, Robert F. and Moons, Karel G.M. and Riley, Richard D. and Whiting, Penny F. and Westwood, Marie and Collins, Gary S. and Reitsma, Johannes B. and Kleijnen, Jos and Mallett, Sue},
	date = {2019-01},
	note = {Publisher: American College of Physicians},
	file = {Accepted Version:/Users/kellya/Zotero/storage/3WDLV4FX/Wolff et al. - 2019 - PROBAST A Tool to Assess the Risk of Bias and App.pdf:application/pdf},
}

@online{noauthor_fate_nodate,
	title = {{FATE}: Fairness, Accountability, Transparency \& Ethics in {AI}},
	url = {https://www.microsoft.com/en-us/research/theme/fate/},
	shorttitle = {{FATE}},
	abstract = {We work on the complex social implications of {AI}, machine learning, data science, large-scale experimentation, and increasing automation.},
	titleaddon = {Microsoft Research},
	langid = {american},
}

@online{noauthor_guide_nodate,
	title = {A guide to machine learning ({ML}) fairness},
	url = {https://www.thinkwithgoogle.com/feature/ml-fairness-for-marketers},
	abstract = {{ML} fairness builds trust, widens reach, and shows customers that their concerns matter. Here are clear steps for developing inclusive {ML}.},
	titleaddon = {Think with Google},
	langid = {american},
}

@software{noauthor_ml-fairness-gym_nodate,
	title = {{ML}-fairness-gym},
	url = {https://github.com/google/ml-fairness-gym},
	abstract = {{ML}-fairness-gym is a set of components for building simple simulations that explore the potential long-run impacts of deploying machine learning-based decision systems in social environments. As the importance of machine learning fairness has become increasingly apparent, recent research has focused on potentially surprising long term behaviors of enforcing measures of fairness that were originally defined in a static setting. Key findings have shown that under specific assumptions in simplified dynamic simulations, long term effects may in fact counteract the desired goals. Achieving a deeper understanding of such long term effects is thus a critical direction for {ML} fairness research. {ML}-fairness-gym implements a generalized framework for studying and probing long term fairness effects in carefully constructed simulation scenarios where a learning agent interacts with an environment over time. This work fits into a larger push in the fair machine learning literature to design decision systems that induce fair outcomes in the long run, and to understand how these systems might differ from those designed to enforce fairness on a one-shot basis.},
	publisher = {Google},
	file = {Snapshot:/Users/kellya/Zotero/storage/RTXXJC4L/ml-fairness-gym.html:text/html},
}

@report{vaithianathan_model_2012,
	title = {A Model for Predicting Readmission Risk in New Zealand},
	rights = {http://www.econstor.eu/dspace/Nutzungsbedingungen},
	url = {http://hdl.handle.net/10419/242509},
	abstract = {Predictive Risk Models which utilize routinely collected data to develop algorithms are used in England to stratify patients according to their hospital admission risk. An individual's risk score can be used as a basis to select patients for hospital avoidance programmes. This paper presents a brief empirical analysis of New Zealand hospital data to create a prediction algorithm and illustrates how a hospital avoidance business case can be developed using the model. A sample of 134,262 patients was analyzed in a Multivariate logistic regression, various socioeconomic factors and indictors of previous admissions were used to predict the probability that a patient is readmitted to hospital within the 12 months following discharge. The key factors for readmission prediction were age, sex, diagnosis of last admission, length of stay and cost-weight of previous admission. The prognostic strength of the algorithm was good, with a randomly selected patient with a future re-admission being 71.2\% more likely to receive a higher risk score than one who will not have a future admission.},
	number = {2012/02},
	institution = {Economics Working Paper Series},
	type = {Working Paper},
	author = {Vaithianathan, Rhema and Jiang, Nan and Ashton, Toni},
	date = {2012},
	file = {Full Text PDF:/Users/kellya/Zotero/storage/AGLE4RFD/Vaithianathan et al. - 2012 - A Model for Predicting Readmission Risk in New Zea.pdf:application/pdf},
}

@report{ai_forum_artificial_2019,
	title = {Artificial Intelligence for Health in New Zealand: Hauora i te Atamai Iahiko},
	url = {https://aiforum.org.nz/wp-content/uploads/2019/10/AI-For-Health-in-New-Zealand.pdf},
	shorttitle = {{AI} for Health in {NZ}},
	author = {{AI Forum}},
	date = {2019-10},
	file = {AI Forum - 2019 - Artificial Intelligence for Health in New Zealand.pdf:/Users/kellya/Zotero/storage/YCM4FR25/AI Forum - 2019 - Artificial Intelligence for Health in New Zealand.pdf:application/pdf},
}

@article{moons_transparent_2015,
	title = {Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis ({TRIPOD}): explanation and elaboration},
	volume = {162},
	issn = {1539-3704},
	doi = {10.7326/M14-0698},
	shorttitle = {Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis ({TRIPOD})},
	abstract = {The {TRIPOD} (Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis) Statement includes a 22-item checklist, which aims to improve the reporting of studies developing, validating, or updating a prediction model, whether for diagnostic or prognostic purposes. The {TRIPOD} Statement aims to improve the transparency of the reporting of a prediction model study regardless of the study methods used. This explanation and elaboration document describes the rationale; clarifies the meaning of each item; and discusses why transparent reporting is important, with a view to assessing risk of bias and clinical usefulness of the prediction model. Each checklist item of the {TRIPOD} Statement is explained in detail and accompanied by published examples of good reporting. The document also provides a valuable reference of issues to consider when designing, conducting, and analyzing prediction model studies. To aid the editorial process and help peer reviewers and, ultimately, readers and systematic reviewers of prediction model studies, it is recommended that authors include a completed checklist in their submission. The {TRIPOD} checklist can also be downloaded from www.tripod-statement.org.},
	pages = {W1--73},
	number = {1},
	journaltitle = {Annals of Internal Medicine},
	shortjournal = {Ann Intern Med},
	author = {Moons, Karel G. M. and Altman, Douglas G. and Reitsma, Johannes B. and Ioannidis, John P. A. and Macaskill, Petra and Steyerberg, Ewout W. and Vickers, Andrew J. and Ransohoff, David F. and Collins, Gary S.},
	date = {2015-01-06},
	pmid = {25560730},
	keywords = {Checklist, Decision Support Techniques, Diagnosis, Guidelines as Topic, Humans, Models, Statistical, Multivariate Analysis, Prognosis, Publishing, Reproducibility of Results},
	file = {Full Text:/Users/kellya/Zotero/storage/8LDKITVN/Moons et al. - 2015 - Transparent Reporting of a multivariable predictio.pdf:application/pdf},
}

@article{norgeot_minimum_2020,
	title = {Minimum information about clinical artificial intelligence modeling: the {MI}-{CLAIM} checklist},
	volume = {26},
	rights = {2020 Springer Nature America, Inc.},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/s41591-020-1041-y},
	doi = {10.1038/s41591-020-1041-y},
	shorttitle = {Minimum information about clinical artificial intelligence modeling},
	abstract = {Here we present the {MI}-{CLAIM} checklist, a tool intended to improve transparent reporting of {AI} algorithms in medicine.},
	pages = {1320--1324},
	number = {9},
	journaltitle = {Nature Medicine},
	shortjournal = {Nat Med},
	author = {Norgeot, Beau and Quer, Giorgio and Beaulieu-Jones, Brett K. and Torkamani, Ali and Dias, Raquel and Gianfrancesco, Milena and Arnaout, Rima and Kohane, Isaac S. and Saria, Suchi and Topol, Eric and Obermeyer, Ziad and Yu, Bin and Butte, Atul J.},
	date = {2020-09},
	langid = {english},
	note = {Number: 9
Publisher: Nature Publishing Group},
	keywords = {Communication and replication, Machine learning},
	file = {Accepted Version:/Users/kellya/Zotero/storage/S9BWQ28T/Norgeot et al. - 2020 - Minimum information about clinical artificial inte.pdf:application/pdf;Snapshot:/Users/kellya/Zotero/storage/Z2LRIFQJ/s41591-020-1041-y.html:text/html},
}

@online{noauthor_mo_nodate,
	title = {Mō te Pokapū - About the Hub},
	url = {https://algorithmhub.co.nz/about},
	file = {Algorithm Hub:/Users/kellya/Zotero/storage/IPY25FQG/about.html:text/html},
}

@book{complex_systems_modelling_group_modelling_2010,
	location = {Providence, Rhode Island},
	title = {Modelling in Healthcare},
	isbn = {978-0-8218-4969-9 978-1-4704-1607-2},
	url = {http://www.ams.org/mbk/074},
	publisher = {American Mathematical Society},
	author = {{Complex Systems Modelling Group}},
	date = {2010-08-11},
	langid = {english},
	doi = {10.1090/mbk/074},
	file = {Complex Systems Modelling Group - 2010 - Modelling in Healthcare.pdf:/Users/kellya/Zotero/storage/YWHB3ETI/Complex Systems Modelling Group - 2010 - Modelling in Healthcare.pdf:application/pdf},
}

@online{noauthor_mlflow_nodate,
	title = {{MLflow} - A platform for the machine learning lifecycle},
	url = {https://mlflow.org/},
	abstract = {An open source platform for the end-to-end machine learning lifecycle},
	titleaddon = {{MLflow}},
	langid = {english},
	file = {Snapshot:/Users/kellya/Zotero/storage/UMWSEUJW/mlflow.org.html:text/html},
}

@online{noauthor_bigmlcom_nodate,
	title = {{BigML}.com},
	url = {https://bigml.com/},
	abstract = {Machine Learning made beautifully simple for everyone. Take your business to the next level with the leading Machine Learning platform.},
	titleaddon = {{BigML}.com - Machine Learning made easy},
}

@online{jenkner_15_2020,
	title = {15 Best Tools for {ML} Experiment Tracking and Management},
	url = {https://neptune.ai/blog/best-ml-experiment-tracking-tools},
	abstract = {While working on a machine learning project, getting good results from a single model-training run is one thing. But keeping all of your machine learning experiments well organized and having a process that lets you draw valid conclusions from them is quite another.  The answer to these needs is experiment tracking. In machine learning, experiment […]},
	titleaddon = {neptune.ai},
	author = {Jenkner, Patrycja},
	date = {2020-02-17},
	langid = {american},
}

@article{dagostino_cardiovascular_2013,
	title = {Cardiovascular Disease Risk Assessment: Insights from Framingham},
	volume = {8},
	issn = {2211-8160},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3673738/},
	doi = {10.1016/j.gheart.2013.01.001},
	shorttitle = {Cardiovascular Disease Risk Assessment},
	abstract = {Cardiovascular disease ({CVD}) is among the leading causes of death and disability worldwide. Since its beginning, the Framingham study has been a leader in identifying {CVD} risk factors. Clinical trials have demonstrated that when the modifiable risk factors are treated and corrected, the chances of {CVD} occurring can be reduced. The Framingham study also recognized that {CVD} risk factors are multifactorial and interact over time to produce {CVD}. In response, Framingham investigators developed the Framingham Risk Functions (also called Framingham Risk Scores) to evaluate the chance or likelihood of developing {CVD} in individuals. These functions are multivariate functions (algorithms) that combine the information in {CVD} risk factors such as sex, age, systolic blood pressure, total cholesterol, high-density lipoprotein cholesterol, smoking behavior, and diabetes status to produce an estimate (or risk) of developing {CVD} or a component of {CVD} (such as coronary heart disease, stroke, peripheral vascular disease, or heart failure) over a fixed time, for example, the next 10 years. These estimates of {CVD} risk are often major inputs in recommending drug treatments such as cholesterol-lowering drugs.},
	pages = {11--23},
	number = {1},
	journaltitle = {Global heart},
	shortjournal = {Glob Heart},
	author = {D’Agostino, Ralph B. and Pencina, Michael J. and Massaro, Joseph M. and Coady, Sean},
	date = {2013-03},
	pmid = {23750335},
	pmcid = {PMC3673738},
	file = {PubMed Central Full Text PDF:/Users/kellya/Zotero/storage/PPUPGQ6I/D’Agostino et al. - 2013 - Cardiovascular Disease Risk Assessment Insights f.pdf:application/pdf},
}

@online{noauthor_rules_nodate,
	title = {Rules of Machine Learning},
	url = {https://developers.google.com/machine-learning/guides/rules-of-ml},
	shorttitle = {Rules of Machine Learning},
	titleaddon = {Google Developers},
	langid = {english},
}

@article{erdemir_credible_2020,
	title = {Credible practice of modeling and simulation in healthcare: ten rules from a multidisciplinary perspective},
	volume = {18},
	issn = {1479-5876},
	url = {https://doi.org/10.1186/s12967-020-02540-4},
	doi = {10.1186/s12967-020-02540-4},
	shorttitle = {Credible practice of modeling and simulation in healthcare},
	abstract = {The complexities of modern biomedicine are rapidly increasing. Thus, modeling and simulation have become increasingly important as a strategy to understand and predict the trajectory of pathophysiology, disease genesis, and disease spread in support of clinical and policy decisions. In such cases, inappropriate or ill-placed trust in the model and simulation outcomes may result in negative outcomes, and hence illustrate the need to formalize the execution and communication of modeling and simulation practices. Although verification and validation have been generally accepted as significant components of a model’s credibility, they cannot be assumed to equate to a holistic credible practice, which includes activities that can impact comprehension and in-depth examination inherent in the development and reuse of the models. For the past several years, the Committee on Credible Practice of Modeling and Simulation in Healthcare, an interdisciplinary group seeded from a U.S. interagency initiative, has worked to codify best practices. Here, we provide Ten Rules for credible practice of modeling and simulation in healthcare developed from a comparative analysis by the Committee’s multidisciplinary membership, followed by a large stakeholder community survey. These rules establish a unified conceptual framework for modeling and simulation design, implementation, evaluation, dissemination and usage across the modeling and simulation life-cycle. While biomedical science and clinical care domains have somewhat different requirements and expectations for credible practice, our study converged on rules that would be useful across a broad swath of model types. In brief, the rules are: (1) Define context clearly. (2) Use contextually appropriate data. (3) Evaluate within context. (4) List limitations explicitly. (5) Use version control. (6) Document appropriately. (7) Disseminate broadly. (8) Get independent reviews. (9) Test competing implementations. (10) Conform to standards. Although some of these are common sense guidelines, we have found that many are often missed or misconstrued, even by seasoned practitioners. Computational models are already widely used in basic science to generate new biomedical knowledge. As they penetrate clinical care and healthcare policy, contributing to personalized and precision medicine, clinical safety will require established guidelines for the credible practice of modeling and simulation in healthcare.},
	pages = {369},
	number = {1},
	journaltitle = {Journal of Translational Medicine},
	shortjournal = {Journal of Translational Medicine},
	author = {Erdemir, Ahmet and Mulugeta, Lealem and Ku, Joy P. and Drach, Andrew and Horner, Marc and Morrison, Tina M. and Peng, Grace C. Y. and Vadigepalli, Rajanikanth and Lytton, William W. and Myers, Jerry G.},
	date = {2020-09-29},
	keywords = {Computational modeling, Computer modeling, Credibility, Healthcare, Reliability, Reproducibility, Simulation, Validation, Verification},
	file = {Full Text PDF:/Users/kellya/Zotero/storage/UGBMXI73/Erdemir et al. - 2020 - Credible practice of modeling and simulation in he.pdf:application/pdf;Snapshot:/Users/kellya/Zotero/storage/J377TU6S/s12967-020-02540-4.html:text/html},
}

@software{noauthor_pandas-profiling_2022,
	title = {pandas-profiling},
	rights = {{MIT}},
	url = {https://github.com/ydataai/pandas-profiling},
	abstract = {Create {HTML} profiling reports from pandas {DataFrame} objects},
	publisher = {{YData}},
	date = {2022-11-07},
	note = {original-date: 2016-01-09T23:47:55Z},
	keywords = {big-data-analytics, data-analysis, data-exploration, data-profiling, data-quality, data-science, deep-learning, eda, exploration, exploratory-data-analysis, hacktoberfest, html-report, jupyter, jupyter-notebook, machine-learning, pandas, pandas-dataframe, pandas-profiling, python, statistics},
}

@online{noauthor_synthea_nodate,
	title = {Synthea},
	url = {https://synthetichealth.github.io/synthea/},
	file = {Synthea:/Users/kellya/Zotero/storage/7HD5A9VY/synthea.html:text/html},
}

@online{noauthor_te_nodate,
	title = {Te Pokapū Hātepe o Aotearoa - New Zealand Algorithm Hub},
	url = {https://algorithmhub.co.nz/},
	abstract = {Kia ngāwari ake te haratau a ngā hātepe ki a Aotearoa. Making algorithms and models more accessible for New Zealand.},
	titleaddon = {Te Pokapū Hātepe o Aotearoa - New Zealand Algorithm Hub},
}

@article{chen_synthetic_2021,
	title = {Synthetic data in machine learning for medicine and healthcare},
	volume = {5},
	rights = {2021 Springer Nature Limited},
	issn = {2157-846X},
	url = {https://www.nature.com/articles/s41551-021-00751-8},
	doi = {10.1038/s41551-021-00751-8},
	abstract = {The proliferation of synthetic data in artificial intelligence for medicine and healthcare raises concerns about the vulnerabilities of the software and the challenges of current policy.},
	pages = {493--497},
	number = {6},
	journaltitle = {Nature Biomedical Engineering},
	shortjournal = {Nat Biomed Eng},
	author = {Chen, Richard J. and Lu, Ming Y. and Chen, Tiffany Y. and Williamson, Drew F. K. and Mahmood, Faisal},
	date = {2021-06},
	langid = {english},
	note = {Number: 6
Publisher: Nature Publishing Group},
	keywords = {Health policy, Image processing, Machine learning, Translational research},
	file = {Full Text PDF:/Users/kellya/Zotero/storage/E9UKTG7X/Chen et al. - 2021 - Synthetic data in machine learning for medicine an.pdf:application/pdf;Snapshot:/Users/kellya/Zotero/storage/6UIJ4N2Y/s41551-021-00751-8.html:text/html},
}

@online{noauthor_health_nodate,
	title = {Health Insurance Portability and Accountability Act of 1996},
	url = {https://aspe.hhs.gov/reports/health-insurance-portability-accountability-act-1996},
	abstract = {{PUBLIC} {LAW} 104-191 104th Congress An Act To amend the Internal Revenue Code of 1986 to improve portability and continuity of health insurance coverage in the group and individual markets, to combat waste, fraud, and abuse in health insurance and health care delivery, to promote the use of medical savings accounts, to improve access to long-term care services and coverage, to simplify the administration of health insurance, and for other purposes.},
	titleaddon = {{ASPE}},
	langid = {english},
	file = {Snapshot:/Users/kellya/Zotero/storage/GPR3HY7R/health-insurance-portability-accountability-act-1996.html:text/html},
}

@online{us_department_of_health__human_services_methods_nodate,
	title = {Methods for De-identification of {PHI}},
	url = {https://www.hhs.gov/hipaa/for-professionals/privacy/special-topics/de-identification/index.html},
	author = {{U.S. Department of Health \& Human Services}},
}

@online{amazon_web_services_sensitive_nodate,
	title = {Sensitive Data Discovery and Protection – Amazon Macie},
	url = {https://aws.amazon.com/macie/},
	abstract = {Amazon Macie is a data security and protection service that uses machine learning ({ML}) and pattern matching to discover sensitive data types, improve visibility on your data security, and more.},
	titleaddon = {Amazon Web Services, Inc.},
	author = {{Amazon Web Services}},
	langid = {american},
}

@online{noauthor_cloud_nodate,
	title = {Cloud Data Loss Prevention},
	url = {https://cloud.google.com/dlp},
	abstract = {Cloud {DLP} enables enterprises to automatically discover, classify, and protect their most sensitive data elements.},
	titleaddon = {Google Cloud},
	langid = {english},
}

@online{noauthor_virtual_nodate,
	title = {The Virtual Health Information Network ({VHIN})},
	url = {https://vhin.co.nz/},
	abstract = {The Virtual Health Information Network ({VHIN}) supports high value and high quality research from linked data, frequently using the {StatsNZ} Integrated Data Infrastructure ({IDI}). The {VHIN} is a network of researchers, analysts and professionals who share and collaborate to use health and social data and generate insights to improve the health and wellbeing of all…},
	langid = {american},
}

@online{virtual_health_information_network_idi_2017,
	title = {{IDI} Guides},
	url = {https://vhin.co.nz/guides/},
	abstract = {We have created a number of guides to help users to get started with the {IDI} and to understand some of the different types of data included in it. These are continually evolving and being added to, and if you have any specific requests for further guides, or indeed any useful information to share, please get in touch with us.},
	author = {{Virtual Health Information Network}},
	date = {2017-06-02},
	langid = {american},
}

@online{health_and_disability_ethics_committees_find_nodate,
	title = {Find out if your study requires {HDEC} review},
	url = {https://ethics.health.govt.nz/hdec-reviews-and-approvals/find-out-if-your-study-requires-hdec-review/},
	author = {{Health and Disability Ethics Committees}},
	file = {Find out if your study requires HDEC review | Health and Disability Ethics Committees:/Users/kellya/Zotero/storage/RUKERB2Q/find-out-if-your-study-requires-hdec-review.html:text/html},
}

@online{noauthor_research_nodate-1,
	title = {Research office},
	url = {https://www.bopdhb.health.nz/learning-and-research/clinical-campus/research-office/},
	abstract = {Research office},
	titleaddon = {Te Whatu Ora Hauora o Toi Bay of Plenty},
	langid = {english},
	file = {Snapshot:/Users/kellya/Zotero/storage/UG4GYBJK/research-office.html:text/html},
}

@online{noauthor_health_nodate-1,
	title = {Health and Disability Ethics Committees},
	url = {https://ethics.health.govt.nz/},
	file = {Home | Health and Disability Ethics Committees:/Users/kellya/Zotero/storage/6W5PF2RC/ethics.health.govt.nz.html:text/html},
}

@online{the_university_of_auckland_auckland_nodate,
	title = {The Auckland Health Research Ethics Committee ({AHREC}) - The University of Auckland},
	url = {https://www.auckland.ac.nz/en/research/about-our-research/human-ethics/ahrec.html},
	author = {{The University of Auckland}},
	file = {The Auckland Health Research Ethics Committee (AHREC) - The University of Auckland:/Users/kellya/Zotero/storage/J5F96AB3/ahrec.html:text/html},
}

@online{noauthor_ethics_nodate,
	title = {Ethics \& Algorithms Toolkit (beta)},
	url = {https://ethicstoolkit.ai/},
	file = {Ethics & Algorithms Toolkit (beta):/Users/kellya/Zotero/storage/IPLM3K4K/ethicstoolkit.ai.html:text/html},
}

@online{national_ethics_advisory_committee_national_nodate,
	title = {National Ethical Standards},
	url = {https://neac.health.govt.nz/national-ethical-standards/},
	author = {{National Ethics Advisory Committee}},
	file = {National Ethical Standards | National Ethics Advisory Committee:/Users/kellya/Zotero/storage/T4VZUU9V/national-ethical-standards.html:text/html},
}

@article{mccradden_research_2022,
	title = {A Research Ethics Framework for the Clinical Translation of Healthcare Machine Learning},
	volume = {22},
	issn = {1526-5161},
	url = {https://doi.org/10.1080/15265161.2021.2013977},
	doi = {10.1080/15265161.2021.2013977},
	abstract = {The application of artificial intelligence and machine learning ({ML}) technologies in healthcare have immense potential to improve the care of patients. While there are some emerging practices surrounding responsible {ML} as well as regulatory frameworks, the traditional role of research ethics oversight has been relatively unexplored regarding its relevance for clinical {ML}. In this paper, we provide a comprehensive research ethics framework that can apply to the systematic inquiry of {ML} research across its development cycle. The pathway consists of three stages: (1) exploratory, hypothesis-generating data access; (2) silent period evaluation; (3) prospective clinical evaluation. We connect each stage to its literature and ethical justification and suggest adaptations to traditional paradigms to suit {ML} while maintaining ethical rigor and the protection of individuals. This pathway can accommodate a multitude of research designs from observational to controlled trials, and the stages can apply individually to a variety of {ML} applications.},
	pages = {8--22},
	number = {5},
	journaltitle = {The American Journal of Bioethics},
	author = {{McCradden}, Melissa D and Anderson, James A and A. Stephenson, Elizabeth and Drysdale, Erik and Erdman, Lauren and Goldenberg, Anna and Zlotnik Shaul, Randi},
	date = {2022-05-04},
	pmid = {35048782},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/15265161.2021.2013977},
	keywords = {A Systemic Approach to the Oversight of Machine Learning Clinical Translation, Bridging the {AI} Chasm: Can {EBM} Address Representation and Fairness in Clinical Machine Learning?, Broadening the Ethical Scope, Challenges of Local Ethics Review in a Global Healthcare {AI} Market, Emerging Paradigms for Ethical Review of Research Using Artificial Intelligence, Ethics committees, health care delivery, human subjects research, informed consent, {IRB} (Institutional Review Board), Promoting Ethical Deployment of Artificial Intelligence and Machine Learning in Healthcare, research ethics, Research on the Clinical Translation of Health Care Machine Learning: Ethicists Experiences on Lessons Learned, Response to Open Peer Commentaries: On Social Harms, Big Tech, and Institutional Accountability, Rethinking the {AI} Chasm, Scaling up the Research Ethics Framework for Healthcare Machine Learning as Global Health Ethics and Governance, The Need for a Global Approach to the Ethical Evaluation of Healthcare Machine Learning},
	file = {Full Text:/Users/kellya/Zotero/storage/DJA899GC/McCradden et al. - 2022 - A Research Ethics Framework for the Clinical Trans.pdf:application/pdf},
}

@report{office_of_the_privacy_commissioner_principles_2018,
	title = {Principles for the safe and effective use of data and analytics},
	url = {https://www.stats.govt.nz/assets/Uploads/Data-leadership-fact-sheets/Principles-safe-and-effective-data-and-analytics-May-2018.pdf},
	author = {{Office of the Privacy Commissioner} and {Statistics NZ}},
	date = {2018-05},
	file = {Office of the Privacy Commissioner and Statistics NZ - Principles for the safe and effective use of data .pdf:/Users/kellya/Zotero/storage/7ZA2EG6D/Office of the Privacy Commissioner and Statistics NZ - Principles for the safe and effective use of data .pdf:application/pdf},
}

@report{colin_gavaghan_government_2019,
	location = {Wellington},
	title = {Government use of artificial intelligence in New Zealand},
	url = {https://data.govt.nz/assets/data-ethics/algorithm/NZLF-report.pdf},
	institution = {New Zealand Law Foundation},
	author = {{Colin Gavaghan} and {Alistair Knott} and {James MacLaurin} and {John Zerilli} and {Joy Liddicoat}},
	date = {2019},
	file = {Colin Gavaghan et al. - 2019 - Government use of artificial intelligence in New Z.pdf:/Users/kellya/Zotero/storage/I4ALWIVA/Colin Gavaghan et al. - 2019 - Government use of artificial intelligence in New Z.pdf:application/pdf},
}

@report{manatu_hauora_ministry_of_health_emerging_nodate,
	title = {Emerging Health Technology Introductory Guidance for safely developing \& using Algorithms in Healthcare},
	author = {{Manatū Hauora Ministry of Health}},
}

@report{statistics_nz_algorithm_2018,
	title = {Algorithm Assessment Report},
	url = {https://data.govt.nz/use-data/analyse-data/government-algorithm-transparency},
	author = {{Statistics NZ}},
	date = {2018-10},
	file = {Statistics NZ - 2018 - Algorithm Assessment Report.pdf:/Users/kellya/Zotero/storage/TIRD8YZU/Statistics NZ - 2018 - Algorithm Assessment Report.pdf:application/pdf},
}

@misc{noauthor_algorithm_2020,
	title = {Algorithm Information Request template},
	url = {https://assets.ctfassets.net/6uj5rbssnusx/1rx38jgFIHgef9O2jVdysL/f4bb1df8d010276410f99f2648e45827/Algorithm_Information_Request_Template.pdf},
	date = {2020-10},
	file = {2020 - Algorithm Information Request template.pdf:/Users/kellya/Zotero/storage/ITT9F62G/2020 - Algorithm Information Request template.pdf:application/pdf},
}

@report{ai_forum_trustworthy_2020,
	title = {Trustworthy {AI} in Aotearoa},
	url = {https://aiforum.org.nz/wp-content/uploads/2020/03/Trustworthy-AI-in-Aotearoa-March-2020.pdf},
	author = {{AI Forum}},
	date = {2020-03},
	file = {AI Forum - 2020 - Trustworthy AI in Aotearoa.pdf:/Users/kellya/Zotero/storage/EHN83WNB/AI Forum - 2020 - Trustworthy AI in Aotearoa.pdf:application/pdf},
}
